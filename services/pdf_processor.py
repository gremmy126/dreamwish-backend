# backend/services/pdf_processor.py
"""
PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê³  GPT Visionìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
"""

import os
import base64
from pathlib import Path
from typing import List, Dict
from openai import AsyncOpenAI
from PIL import Image
import fitz  # PyMuPDF

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))


async def process_pdf_and_save_to_vectordb(pdf_path: str) -> bool:
    """
    PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° DBì— ì €ì¥
    """
    try:
        from langchain_community.document_loaders import PyMuPDFLoader
        from langchain_text_splitters import RecursiveCharacterTextSplitter
        from langchain_community.embeddings import OpenAIEmbeddings
        from langchain_community.vectorstores import FAISS
        
        # PDF ë¡œë“œ
        loader = PyMuPDFLoader(pdf_path)
        documents = loader.load()
        
        if not documents:
            print(f"âš ï¸ {pdf_path}ì—ì„œ ë¬¸ì„œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ì²­í¬ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100,
        )
        chunks = text_splitter.split_documents(documents)
        
        if not chunks:
            print(f"âš ï¸ {pdf_path}ì—ì„œ ì²­í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ë²¡í„° DBì— ì €ì¥
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        faiss_path = "faiss_index"
        
        if os.path.exists(faiss_path):
            # ê¸°ì¡´ ì¸ë±ìŠ¤ì— ì¶”ê°€
            vector_store = FAISS.load_local(faiss_path, embeddings, allow_dangerous_deserialization=True)
            vector_store.add_documents(chunks)
        else:
            # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
            vector_store = FAISS.from_documents(chunks, embeddings)
        
        # ì €ì¥
        vector_store.save_local(faiss_path)
        print(f"âœ… {pdf_path} ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ì €ì¥")
        return True
    
    except Exception as e:
        print(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ ({pdf_path}): {e}")
        return False


class PDFProcessor:
    """PDF ì´ë¯¸ì§€ë¥¼ GPT Visionìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    
    def __init__(self):
        self.image_folder = Path("PDF_ì´ë¯¸ì§€")
        self.temp_folder = Path("PDF_ì„ì‹œí´ë”")
    
    def encode_image(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    async def extract_text_from_image(self, image_path: str) -> str:
        """GPT Vision APIë¡œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            base64_image = self.encode_image(image_path)
            
            response = await client.chat.completions.create(
                model="gpt-4o",  # GPT-4 Vision
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë“œë¦¼ìœ„ì‹œ í”Œë«í¼ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤. 
ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³ , 
í”Œë«í¼ ê¸°ëŠ¥, ì‚¬ìš©ë²•, ì„œë¹„ìŠ¤ ì„¤ëª… ë“±ì„ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.

ì¶”ì¶œ í˜•ì‹:
- ì œëª©/ì†Œì œëª©ì€ ëª…í™•í•˜ê²Œ êµ¬ë¶„
- ì£¼ìš” ê¸°ëŠ¥ê³¼ ì„¤ëª…ì„ í•­ëª©ë³„ë¡œ ì •ë¦¬
- ìˆ«ì, í†µê³„, ë‚ ì§œ ë“±ì€ ì •í™•í•˜ê²Œ ê¸°ë¡
- í‘œë‚˜ ë‹¤ì´ì–´ê·¸ë¨ì€ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…"""
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "ì´ ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ì™€ ë‚´ìš©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë“œë¦¼ìœ„ì‹œ í”Œë«í¼ì— ê´€í•œ ì •ë³´ì…ë‹ˆë‹¤."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.2
            )
            
            return response.choices[0].message.content or ""
        
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ({image_path}): {e}")
            return ""
    
    async def process_all_images(self) -> List[Dict[str, str]]:
        """ëª¨ë“  PDF ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        documents = []
        
        if not self.image_folder.exists():
            print(f"âš ï¸ ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {self.image_folder}")
            return documents
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì •ë ¬)
        image_files = sorted(
            [f for f in self.image_folder.glob("*.png")],
            key=lambda x: int(x.stem.split('_')[1]) if '_' in x.stem else 0
        )
        
        print(f"ğŸ“„ {len(image_files)}ê°œì˜ PDF ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
        
        for idx, image_path in enumerate(image_files, 1):
            print(f"  [{idx}/{len(image_files)}] {image_path.name} ì²˜ë¦¬ ì¤‘...")
            
            text = await self.extract_text_from_image(str(image_path))
            
            if text:
                documents.append({
                    "page_content": text,
                    "metadata": {
                        "source": str(image_path),
                        "page": idx,
                        "category": "dreamwish_platform"
                    }
                })
                print(f"  âœ… {image_path.name} ì™„ë£Œ ({len(text)} ê¸€ì)")
            else:
                print(f"  âš ï¸ {image_path.name} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
        
        print(f"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ì¶”ì¶œ ì™„ë£Œ")
        return documents


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
pdf_processor = PDFProcessor()
